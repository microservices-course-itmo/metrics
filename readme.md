# Метрики

Метрики - это один из способов отслеживания состояния сервисов в режиме реального времени. В нашей системе используется Prometheus–централизованная система по сбору, хранению и обработки метрических данных, и Grafana–система по визуализации накопленных данных.

# Запуск системы

Скопируйте репозиторий при помощи команды
```bash
git clone https://github.com/microservices-course-itmo/metrics
```

После этого, необходимо запустить контейнеры, прописанные в файле docker-compose.yml . Сделать это можно либо при помощи непосредственно docker-compose:

```bash
docker-compose up
```

Или при помощи docker stack

```bash
docker swarm init
docker stack deploy --compose-file docker-compose.yml metrics
```

Теперь вы можете перейти на localhost:9090 (Prometheus) и localhost:3000 (Grafana) для дальнейшей работы.

> Если вы запускаете Grafana впервые, то изначально существует один пользователь admin с паролем admin. После авторизации вам предложат сменить пароль. Вы можете пропустить этот шаг.

# Настройка Prometheus

Настройка сервера Prometheus осуществляется при помощи файла prometheus.yml Ниже приведено содержание файла.

```yaml
global:
  scrape_interval: 15s
  scrape_timeout: 10s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'choreographer'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['host.docker.internal:8080']
```

## Описание свойств

- `global` – конфигурация глобальных значений задач. Значения можно перезаписывать для конкретно поставленной задачи.

    `scrape_interval` – интервал с которым система будет собирать метрики с поставленных задач.

    `scrape_timeout` – временной промежуток, за который система инвалидирует запрос.

- `scrape_configs` – конфигурации задач.

    `job_name` – идентификатор задачи

    `metrics_path` – HTTP ресурс (URL) на котором расположены метрики (по стандарту `/metrics`)

    - `static_configs`

        `targets` – список статически неменяющихся IP, с которых будут собираться значения.

## Задачи

Секция `scrape_config` содержит список поставленных задач, которые мы хотим исполнять в нашей системе. Интервал их выполнения зависит от значения `global.scrape_interval`. Либо может быть перезаписан для конкретного случая.

В первую очередь необходимо определить job_name для задачи. Оно должно быть уникальным во всем списке. 

Во-вторых, необходимо использовать Service Discovery для нахождения целей сбора данных конкретной задачи, *или* прописать адреса статически. В данном случае, мы воспользовались вторым способом, указав список из одного элемента. В случае, если элементов несколько: укажите через запятую IP адреса (например `['192.168.0.1:8080', '192.168.0.2:8080', ...]`). Можно совмещать эти два способа, при необходимости.

> host.docker.internal – адрес, на котором запущен сервер докера

Если адрес ресурса для сбора данных, отличается от стандартного (`/metrics`), то  укажите соотвествующий адрес в `metrics_path`.

Когда система будет собирать данные, то ко всем метрикам будут добавлены две метки: `job` и `instance`. Первый будет получен из объявленного в файле `job_name`. Второй – в зависимости от IP адреса сбора данных.

---

Так как мы используем контейнеры для работы системы, то необходимо предать этот файл внутрь него. В `docker-compose.yml` , который вы скачали ранее – **данная настройка уже сделана.** Для дальнейшей конфигурации сервиса, вам достаточно изменить содержание файла конфигурации и перезапустить контейнер.

> Стоит отметить, что задача choreographer содержит два ресурса с метриками. В файле конфигурации мы используем лишь один из них, сгенерированный при помощи Micrometer, так как он даёт больше всего информации о сервисе